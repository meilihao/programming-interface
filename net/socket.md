# socket

- socket.connect() 是通信双方交换控制信息, 尝试建立一个连接
    通信操作中使用的控制信息分为两类:
    1. 头部(以太网头部, IP头部, TCP头部等)中记录的信息
    2. 套接字（协议栈中的内存空间）中记录的信息
- socket.bind() : 为新建的socket绑定一个本地网络地址.
- socket.listen() : 为新socket分配缓存空间, 并给出队列大小
- socket.accept() : 阻塞调用方, 直到有连接进入
    新连接进来时socket调用accept原语创建一个新socket并返回一个与其关联的文件描述符, 旧socket继续监听.
- socket.send() : 向socket发送数据
- socket.recv() : 从socket接收数据
- socket.close() : 释放socket

> 网络字节序是大端序

> 在网络层, Socket 函数需要指定到底是 IPv4 还是 IPv6,分别对应设置为 AF_INET 和 AF_INET6

> 在传输层, TCP 协议是基于数据流的,所以设置为SOCK_STREAM,而 UDP 是基于数据报的,因而设置为 SOCK_DGRAM

端口分类:
- 保留端口: 0~1023
- 动态分配端口(也叫非特权端口): > 1024
- 注册端口: > 1024

## 原理
参考:
- [epoll 的本质是什么？](https://my.oschina.net/editorial-story/blog/3052308)
- [从linux源码看epoll](https://www.jishuwen.com/d/2dNT)

### 基于 TCP 协议的 Socket 函数调用过程:
![](/misc/img/net/v2-067f27c436ae555b059c4a0792e556a1_hd.jpg)

在内核中,为每个 Socket 维护两个队列: 
1. 一个是已经建立了连接的队列,这时候连接三次握手已经完毕,处于 established 状态
2. 一个是还没有完全建立连接的队列,这个时候三次握手还没完成,处于syn_rcvd 的状态

默认情况，内核会认为socket函数创建的套接字是主动套接字（active socket），它存在于一个连接的客户端. 而服务器调用listen函数告诉内核，该套接字是被服务器而不是客户端使用的，即listen函数将一个主动套接字转化为**监听socket**. 监听套接字可以接受来自客户端的连接请求. 服务器通过accept函数等待来自客户端的连接请求到达监听套接字, 处理后返回一个**已连接socket**.

socket内核描述:
![](/misc/img/net/qsrseeds2x.png)

每一个进程都有一个数据结构 task_struct，里面指向一个文件描述符数组fds，来列出这个进程打开的所有文件的文件描述符. 该数组中的内容是一个指针，指向内核中所有打开的文件列表, 而每个文件也会有一个 inode（索引节点）.

对于 Socke 而言，它是一个文件，也就有对于的文件描述符. 与真正的文件系统不一样的是，Socket 对于的 inode 并不是保存在硬盘上，而是在内存中. 在这个 inode 中，指向了 Socket 在内核中的 Socket 结构.

 在这个结构里面，主要有两个队列: 一个发送队列sk_write_queue，一个接收队列sk_receive_queue. 这两个队列里面，各保存一个 sk_buff chain作为缓存. 在这个缓存里能够看到完整的package结构.

系统会用一个四元组来标识一个 TCP 连接: `本机 IP, 本机端口, 对端 IP, 对端端口`.

服务端最大并发 TCP 连接数远不能达到理论上限(对端IP * 对端端口 = 2^32 * 2^16):
- 文件描述符限制, 因为Socket 是文件, 受到 ulimit 配置文件描述符的数目限制
- 内存, 每个 TCP 连接都要占用一定内存

提升tcp连接数量的方式:
1. 多进程方式(不推荐, 太耗资源)
    因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的. 因此父进程刚才因为 accept 创建的已连接 Socket 也是一个文件描述符，同样也会被子进程获得.

    接下来，子进程就可以通过这个已连接 Socket 和客户端进行通信了. 当通信完成后，就可以 退出进程. 那父进程如何知道子进程干完了项目要退出呢？父进程中 fork 函数返回的整数就是子进程的 ID，父进程可以通过这个 ID 查看子进程是否完成项目，是否需要退出.
1. 多线程方式
    在 Linux 下，通过 pthread_create 创建一个线程，也是调用 do_fork. 不同的是，虽然新的线程在 task 列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，这些还是共享的，只不过多了一个引用而已.
1. IO 多路复用，一个线程维护多个 Socket
    Socket 是文件描述符，因此某个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中, 然后调用 select 函数来监听文件描述符集合是否有变化(其监视数量受FD_SETSIZE 限制)，一旦有变化，就会依次轮循查看每个文件描述符. 那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化.
1. IO 多路复用, select(轮循)到epoll(事件通知)
    epoll在内核中的实现不是通过轮询的方式,而是通过注册 callback 函数的方式,当某个文件描述符发送变化的时候,就会主动通知.

    ![](/misc/img/net/zqugepbmve.png)

    epoll_create 创建一个 epoll 对象,也是一个文件,也对应一个文件描述符,同样也对应着打开文件列表中的一项. 在这项里面有一个红黑树,在红黑树里,要保存这个 epoll要监听的所有 Socket.

    当 epoll_ctl 添加一个 Socket 的时候,其实是加入这个红黑树,同时红黑树里面的节点指向一个结构, 将这个结构挂在被监听的 Socket 的事件列表中. 当一个 Socket 来了一个事件的时候,可以从这个列表中得到 epoll 对象,并调用 call back 通知它.

    这种通知方式使得监听的 Socket 数据增加的时候,效率不会大幅度降低,能够同时监听的 Socket 的数目也非常的多了, 上限就为系统定义的进程打开的最大文件描述符个数. 因而,epoll 被称为解决C10K 问题的利器

### 基于 UDP 协议的 Socket 程序函数调用过程
![](/misc/img/net/qofe1t7ocm.png)

UDP 是没有连接的,所以不需要三次握手,也就不需要调用 listen 和 connect,但是,UDP 的的交互仍然需要 IP 和端口号,因而也需要 bind. 同样因为UDP 是没有维护连接状态的,因而不需要每对连接建立一组 Socket,而是只要有一个 Socket就能够和多个客户端通信.

## FAQ
### socket 阻塞与非阻塞的区别(面试)
阻塞: 在socket中调用recv函数，如果缓冲区中没有数据，这个函数就会一直等待，直到有数据才返回.

非阻塞: 调用recv()函数读取网络缓冲区中数据，不管是否读到数据都立即返回，而不会一直挂在此函数调用上.

### epoll 和 select 的区别
1. epoll 和 select 都是 I/O 多路复用的技术,都可以实现同时监听多个 I/O 事件的状态
1. epoll 相比 select 效率更高,主要是基于其操作系统支持的 I/O事件通知机制, 而 select 是基于轮询机制
1. epoll 支持水平触发和边沿触发两种模式