# 分布式存储
特点:
1. 可扩展
1. 低成本
1. 高性能

    维度: 吞吐量和访问延迟
1. 易用
1. 高可用

难点: 数据和状态的持久化, 要求在自动迁移,自动容错,并发读写的过程中保证数据的一致性.
核心相关领域: 分布式系统, 分布式DB

相关内容:
1. 数据分布
1. 多副本一致性
1. 容错
1. 负载均衡
1. 事务与并发控制
1. 易用性
1. 解压缩

分布式存储系统分类:
1. 分布式文件系统
    
    以对象(图片, 视频等非结构化数据)的形式组织, 对象间没有关联, 该类数据被称为blob(binary large object, 二进制大对象).

    比如Facebook haystack, taobao file system(TFS) 
1. 分布式kv系统

    amazon dynamo, tabao tair, tikv
1. 分布式表格系统

    google bigtable, amazon dynamodb
1. 分布式数据库

    google spanner, tidb, oceanbase

> 分布式表格系统主要针对单表操作, 不支持一些特别复杂的操作: 多表关联, 嵌套子查询等.

## 对象存储
对象 = 数据 + 元数据

## 纠删码(erasure code)
纠删码是一种恢复丢失和损坏数据的数学算法，目前，纠删码技术在分布式存储系统中的应用主要有三类:
- 阵列纠删码（Array Code: RAID5、RAID6等）
- RS(Reed-Solomon)里德-所罗门类纠删码
- LDPC(LowDensity Parity Check Code)低密度奇偶校验纠删码

    与RS编码相比，LDPC编码效率要略低，但编码和解码性能要优于RS码以及其他的纠删码，主要得益于编解码采用的相对较少并且简单的异或操作. LDPC码目前主要用于通信、视频和音频编码等领域

Erasure Code是一种编码技术，它可以将n份原始数据，增加m份数据，并能通过n+m份中的任意n份数据，还原为原始数据, 即如果**有任意小于等于m份的数据失效，仍然能通过剩下的数据还原出来**, 简单的说就是**纠删码最多能容忍m个数据块被删除**.

HDFS、盘古等是多副本模式(比如3副本)，只要还有一个机器在，数据就不会丢失, 但这样磁盘的利用率其实挺低的，只有原始容量的1/3; minio使用的是erasure code, 磁盘利用率为n/(n+m), n为原始数据块, m为校验块. 与多副本相比, erasure code可认为是用cpu利用率节省磁盘空间.

基于纠删码的方法与多副本方法相比具有冗余度低、磁盘利用率高等优点，但计算、网络开销大，恢复效率低. 就场景而言, ec适合冷数据场景:
1. 冷数据集群往往有大量的长期没有被访问的数据，体量确实很大，采用EC技术，可以大大减少副本数  
1. 冷数据集群基本稳定，耗资源量少，所以一旦进行数据恢复，将不会对集群造成大的影响

存储系统通常使用[RS(Reed Solomon)码](https://juejin.cn/post/6844903460928913421), 这里有一个golang的[reedsolomon](https://github.com/klauspost/reedsolomon).

> 阿里盘古使用`N+3`形式的纠删码

> 进行EC编码的前提是每个块的长度一致. 如果不一致，则应填充0.

RAID与删码区别:
- EC算法采用全局热备的方式，不需要单独的热备盘，所有硬盘都可参与数据读写，只要系统中有剩余空间，就可以恢复故障数据；RAID5方式单节点至少准备一块全局热备盘
- EC算法通常是跨节点的，4+2:1的冗余允许1个节点故障而不丢失数据，RAID5一般是由节点内的若干块盘组成RAID组的，只能容忍硬盘故障，不能容忍节点故障
- 4+2:1的EC方式允许损害任意的2块盘而不丢失数据，RAID5方式每个RAID组最多只允许损害1块盘，所谓的允许损坏多块盘是建立在所有坏盘都不位于相同RAID组中的，从实际经验来看，把数据安全建立在理想情况下是不靠谱的
- 当出现硬盘故障时，EC方式是多块盘参与数据恢复，RAID方式只有1块盘（热备盘）能够写数据，这就导致EC方式的数据恢复效率（1TB/小时）是RAID方式的几十倍，这也大大减少了数据恢复期间硬盘再次故障的可能（目前单盘容量都达到数个TB使得该风险急剧增加），进一步提升了系统的安全性
- EC方式的保护级别可以针对目录设置，重要的数据目录可以设置更高的保护级别以确保安全性，随着节点扩容，数据条带大小还能自动调整以获取更高的空间利用率；RAID方式所有数据的保护级别是相同的，RAID组一旦划分完不能够再调整(zfs之类的软raid除外)
- RAID方式需要独立的RAID卡(软raid除外)，EC方式不需要额外的硬件支持

可靠性对比:
- EC 配置 1 个校验位（FT=1） 与 2 副本（RF=2） 的可靠性相当，允许任意 1 个节点或者 1个数据块损坏
- EC 配置 2个校验位（FT=2） 与 3 副本（RF=3） 的可靠性相当，允许任意 2 个节点或者2 个数据块损坏

数据恢复对性能影响:
- 2 副本下，1 个节点或者数据块故障，数据恢复需要从一个副本读取一次，然后写入一次进行恢复副本，影响 1 个节点的读取性能
- EC 设置 4/1 情况下，1 个节点或者数据块故障，数据恢复需要读取 3 个数据块和 1 个校验，通过运算后写入一次进行数据恢复，影响 4 个节点的读取性能

写惩罚:
- 2 副本下，某个节点的 1 次数据写入，实际需要 2 个节点参与（写入 2 次），写惩罚为 2
- EC 设置 4/1 情况下，1 次数据写入，实际需要至少 2 个节点参与，其中读取 2 次（读取数据，读取校验），写入 2 次（写入数据，写入校验），写惩罚为 4

CPU 开销:
- 2 副本/ 3 副本是基于数据完整复制，没有涉及额外的运算，对 CPU 开销较低
- EC 由于读写都需要计算校验值，需要额外的 CPU 资源开销


两种技术对比(磁盘利用率/计算开销/网络消耗/恢复效率):
- 多副本(3副本)    1/3 几乎没有    较低  较高
- 纠删码(n+m)    n/(n+m) 高(进行编码，解码计算需要消耗CPU资源)   较高(数据恢复需要去读其他的数据块和校验块)  较低

## checksum
checksum, 比如[高速HighwayHash(基于哈希的校验)](https://github.com/minio/highwayhash)可判别数据受硬件故障和静默数据损坏(也叫位衰减bit rot, 或数据腐化Data Rot, 或无声数据损坏Silent Data Corruption), 再结合erasure code/多副本机制, 可确保数据不损坏.

## 单机存储引擎
单机存储引擎是hash表, BTree等数据结构在HDD和SSD等持久化介质上的实现.

hash: 不支持顺序扫描 -> kv
BTree: 支持顺序扫描 -> 关系DB

LSM(log structure merge tree)存储引擎是采用批量转储技术来避免磁盘随机写入, 思想是将对数据的修改增量保持在内存中, 达到指定大小限制后将这些修改批量写入磁盘, 读取时需要合并磁盘中的历史数据和内存中最近的修改记录.

缓冲管理:
- LRU : 淘汰最长时间没有读/写的块
- LIRS : 分层LRU

    避免全表扫描时LRU被大量替换.

    实现: oracle db的touch count算法, mysql innodb中的替换算法

将内存中的数据定期转储(dump)到磁盘, 即为checkpoint(检查点)技术.

## 协议
gossip用于p2p系统中自治的节点协调对整个集群的认识, 比如集群的节点状态, 负载情况等.

## 现状
从amazon, facebook等公司的实践经验来看, dynamo及其开源实现Cassandra受到的关注在递减, 无中心节点的设计在当前难以成为主流, 毕竟中心节点更容易处理数据的一致性, 而且中心节点只维护少量的元数据, 一般不会成为性能瓶颈.

## 实现
- [分布式块存储系统Ursa的设计与实现](https://tech.meituan.com/2016/03/11/block-store.html)