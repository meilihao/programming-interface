# aarch64
## 特权级
- EL0: 最低的特权级, 应用程序通常运行在该级别, 也称为用户态
- EL1: os通常运行在该级别, 也称为内核态
- EL2： 在虚拟化场景下需要, VMM(即Hypervisor)通常运行在该级别
- EL3: 和安全特性TrustZone相关, 负责normal world和secure world之间的切换

EL0切换到EL1的可能场景:
1. 应用程序调用os的系统调用即执行svc指令

	ARM Linux 的系统调用实现原理是采用 swi 软中断从用户（usr）模式陷入管理模式（svc）
1. 应用程序执行触发异常(exception), 比如缺页异常(page fault)
1. 应用程序在执行过程中, cpu收到一个来自外设的中断

前2种由应用程序导致的场景统称为同步的cpu特权级切换, 第3种则是异步的cpu特权级切换.

EL0切换到EL1的, cpu保存的主要状态:
1. 触发异常的指令地址(即当前程序计数器PC), 保存在ELR_EL1(异常链接寄存器, ExceptionLinkRegjster)中
1. 异常原因(即异常是由于执行svc指令还是由于访存缺页导致的), 保存在ESR_EL1(异常症状寄存器ExceptionSyndromeRegister)中
1. CPU将浅指针（StackPointer, SP）从SP_EL0（应用程序使用的栈）切换到SP_EL1（操作系统可以通过设置这个寄存器来配置异常处理过程中使用的栈）
1. CPU还会保存一些其他状态, 例如将CPU的相关状态保存在SPSR_EL1（已保存的程序状态寄存器, SavedProgramStatusRegister）中, 将引发缺页异常的地址保存在FAR_EL1（错误地址寄存器FaultAddressRegister）中

os可以在异常向量表中为不同的异常类型配置相应的异常处理函数. 当发生特权级切换时, CPU会读取VBAR_EL1（向量基地址寄存器, VectorBaseAddressRcgjster）来获得异常向量表（exception vector table）的基地址, 然后根据异常原因（ESR_EL1中保存的内容）调用操作系统设置的相应异常处理函数. 之后, os中的相应异常处理函数开始执行. 一般来说该函数会先保存应用程序的上下文（比如通
用寄存器), 以防os在执行过程中破坏这些状态,然后会根据异常原因进行相应
的处理. 处理完成后, os会恢复应用程序的上下文, 然后执行eret（异常返回, ExceptionReturn）指令以恢复CPU自动保存的EL0状态（包括PC和SP等）, 并切回到EL0, 使应用程序从被中断处继续执行.

## 寄存器
在AArch64中, 有31个64位通用寄存器被命名为X0～X30, 其中X29用作帧指针（FramePointer, FP）寄存器, 按照使用惯例, 一般用于保存函数调用过程中栈顶的地址; X30用作链接指针（LinkPointer, LP）寄
存器, 因为CPU在执行函数调用指令b1时会自动把返回地址保存在其中.

在EL1特权级下有两个页表基地址寄存器（TranslatlonTableBaseRegister, TTBR）即TTBR0_EL1和TTBR1_EL1, 它们负责翻译虚拟地址空间中不同的地址段, 负责的地址范围由另一个控制寄存器TCR_EL1（翻译控制寄存器, TranslatjonControlRegister）决定. os中一种常见的配置是TTBR0_EL1负责［0, 2^48）的地址映射（作为用户地址空间）, TTBR1_EL1负责［2^48,2^64）的地址映射（作为操作系统
内核地址空间）.

## 缓存结构
CPU缓存是由若干个缓存行（cacheline）组成的. 每个缓存行包括:一个有效位（valid bit）, 用于表示其是否有效; 一个标记地址（tag address）, 用于标识其对应的物理地址; 一些其他的状态信息. 通常CPU以缓存行（常见的是64字节）为单位把物理内存中的数据读取到CPU缓存中, 因此即使只需要单个字节的值, 该字节对应的缓存行也会全部进人缓存中. 同样.将数据写回到物理内存也是以缓存行为单位的.

为了通过内存的物理地址找到对应的缓存. 物理地址在逻辑上分为Tag、Set（也称为Index）以及Offset三段. 组（Set）与路（Way）是CPU缓存的经典概念. 物理地址中的Set段能表示的最大数目称为组. 如果
Set段的位数是8, 那么对应的CPU缓存的组数就是256（2^8＝256）. 同—组（即Set段相等）下, 支持的最大Tag数则称为路, 即同一组下的缓存行数目.

## MMIO
内存映射输入输出(Memory-Mapped I/O, MMIO)是一种常见的cpu控制和访问设备的方式. 其原理是: 把输入输出设备和物理内存放在同一个地址空间, 为设备内部的内存和寄存器也分配相应的地址, cpu通过这些地址去访问操作设备, 设备通过总线监听cpu分配给自己的地址, 去完成相应的cpu请求.

AArch64将MMIO作为CPU控制和访问设备的重要方式.

MMIO使得CPU可以主动地访问设备, 中断使得设备能够主动地通知CPU, 这两种机制是CPU与设备之间交互的重要方式.

## 中断
中断（interrupt）机制就赋予了设备通知CPU的能力.

## 页表
AArch64采用常见的页表设置, 即虚拟地址低48位参与地址翻译, 页表级数为4级, 虚拟页大小为4KB, 具体是:
1. 第63至48位:全为0或者全为1（硬件要求）, 通常os的选择是应用程序使用的虚拟地址的这些位都是0, 即应用程序的虚拟地址空间是2^48
1. 第47至39位: 这9位作为该虚拟地址在第0级页表中的索引值
1. 第38至30位: 这9位作为该虚拟地址在第1级页表中的索引值
1. 第29至21位: 这9位作为该虚拟地址在第2级页表中的索引值
1. 第20至12位: 这9位作为该虚拟地址在第3级页表中的索引值
1. 第11至0位: 由于页的大小是4KB, 所以低12位代表页内偏移量

整个页表的起始地址（物理地址）存储在一个特殊的寄存器中, 对于包括Linux在内的主流操作系统上的用户地址空间来说, 这个页表基地址寄存器是TTBR0_EL1, 页表基地址寄存器存储的就是该页的物
理地址; kernel也使用独立的页表, 该页表基地址寄存器是TTBR1_EL1, 且第63至48位全为1.

当MMU翻译一个虚拟地址时, 首先根据页表基地址寄存器中的物理地址找到第0级页表页, 然后将虚拟地址的虚拟页号0（第47至39位）作为页表项索引, 读取0级页表页中的相应页表项;该页表项中存储着下一级（第1级）页表页的物理地址, MMU按照类似的方式将虚拟地址的虚拟页号1（第38至30位）作为页表项索引, 继续
读取第1级页表页中的相应页表项; 往下类推, MMU将在一个第3级页表页中的页表项里面找到该虚拟地址对应的物理页号, 再结合虚拟地址中的页内偏移量即可获得最终的物理地址.

### TLB
多级页表结构能够显著地压缩页表大小, 但是会导致地址翻译时长的增加（`时间换空间`的权衡).

为了减少地址翻译的访存次数, MMU引人转址旁路缓存（TranslationLookasideBufIer, TLB, 基于局部性原理）部件来加速地址翻译的过程, 因为TLB缓存了虚拟页号到物理页号的映射关系.

通过TLB能够直接完成地址翻译的过程为TLB命中（TLB hit）;反之为TLB未命中（TLBmiss）.

一般来说, TLB硬件采用分层的架构（类似于CPU缓存）分为L1和L2两层. 其中L1又分为数据TLB和指令TLB, 分别用于缓存数据和指令的地址翻译; L2不区分数据和指令（也存在分离的设计）.

作为CPU内部的硬件部件TLB的体积实际上是极小的, 这也就意味着其缓存项的数量是极其有限的. 例如在树梅派4使用的AArch64 Cortex A72 CPU中, 每个CPU核心只有约一千条TLB缓存项. 在主流的AArch64和x86_64体系结构下, TLB在地址翻译过程中是由硬件（MMU）进行管理的, 以保证其效率.

os在进行页表切换（应用程序切换）的时候需要主动刷新TLB; kernel不需要刷新:
1. 在AArch64, 通常应用程序和操作系统使用不同的页表, 即TTBR0_EL1和TTBR1_EL1这两个不同的页表基地址寄存器可供它们分别使用, 因此在系统调用过程中不需要切换页表
1. x86_64体系结构只提供一个页表基地址寄存器CR3, os通常不使用单独的页表, 而把自己映射到应用程序页表中的高地址部分, 从而在系统调用过程中也不需要切换页表

应用程序切换时刷新TLB, 那么程序刚开始时可能总会出现TLB未命中的情况. 因此一种为TLB缓存项打上`标签`的设计正是为了避免这样的开销. 以AArch64体系结构为例, 它提供了ASID（Address
Space IDentifier）功能（x86_64上对应的功能称为PCID, ProcessContext IDentifier）. 具体来说, os可以为不同的应用程序分配不同的ASID作为应用程序的身份标签, 
再将这个标签写人应用程序的页表基地址寄存器中的空闲位（如TTBR0_EL1的高16位）, 同时TLB中的缓存项也会包含ASID这个标签, 从而使得TLB中属于不同应用
程序的缓存项可以被区分开. 因此在切换页表的过程中,操作系统不再需要清空TLB缓存项.

在修改页表内容之后, os需要主动刷新TLB以保证TLB缓存和页表项内容—致. 在AArch64体系结构中提供了多种不同粒度的刷新TLB指
令, 包括刷新全部TLB/刷新指定ASID的TLB/刷新指定虚拟地址的TLB等.

## 换页与缺页
在x86_64体系结构上, 缺页并常会触发13号异常（＃PF）, 并且访问出错的虚拟地址会被放在CR2寄存器中. 在AArch64, 缺页并常并没有一个专门的异常号, 而是与其他一些用户态同步异常共用一个异常号(8号同步并常), os根据ESR（ErrorSyndromeRegister）寄存器中存储的信息来判断发生的异常是否为缺页异常, 如采是则从FAR_EL1寄存器中取出发生缺页异常时访问的虚拟地址

在linux中, 应用程序的虚拟地址空间被实现成由多个虚拟内存区域（VirtualMemoryArea, VMA）组成的数据结构. 每个虚拟内存区域中包含该区域的起始虚拟地址, 结束虚拟地址, 访问权限等信息. 当应用程序发生缺页异常时（假设访问虚拟页P）. os（缺页异常处理函数）通过判断虚拟页P是否属于该应用程序的某个虚拟内存区域来区分该页所处的分配状态: 若属于, 则说明该页处于已分配但未映射至物理内存状态;若不属于, 则说明该页处于未分配状态.

## 虚拟内存功能
### 共享内存
共享内存的一个基本用途就是让不同的应用程序之间相互通信, 传递数据. 此外, 基于共享内存的思想, os还衍生出了写时拷贝(copy-on-write）、内存去重（memorydeduplication）等功能

### 写时拷贝
一个页表项的大小是64位, 其中第47位至第12位用来存储物理地址（物理页号）, 剩下的位多为属性位（attribute bit）, 包括用于标识虚拟页的权限（该页是否可写、可执行）的权限位等. 写时
拷贝正是利用表示`是否可写`的权限位来实现的.

写时拷贝技术允许应用程序A, B以只读的方式（在页表项中清除可写位）共享同一段物理内存. 一旦某个应用程序对该内存区域进行修改, 就会触发缺页异常. 该缺页异常是由于违反权限导致的, 不同于之前所说的换页机制下的缺页异常是由于未映射导致的. 在触发了缺页异常后, CPU同样会将控制流传递给os预先设置的缺页异常处理函数. 在该函数中, os会发现当前的缺页异常是由于应用程序写了只读内存, 而且相应的内存区域又是被os标记成写时拷贝的. 于是, os会在物理内存中将缺页异常对应的物理页重新拷贝一份, 并且将新拷贝的物理页以可读可写的方式重新映射给触发异常的应用程序, 此后再恢复应用程序的执行.

### 内存去重
os定期地在内存中扫描具有相同内容的物理页, 并且找到映射到这些物理页的虚拟页; 然后只保留其中一个物理页, 并将具有相同内容的其他虚拟页都用写时拷贝的方式映射到这个物理页, 然后释放其他的物理页以供将来使用. 该功能通常由os主动发起使用, 对于用户态应用程序完全透明.

Linux里是KSM（Kernel Same-page Merging）. 内存去重功能会对应用程序访存时延造成影响:当应用程序写一个被去重的内存页时, 既会触发缺贞异常, 又会导致内存拷贝, 从而可能导致性能下降.

### 内存压缩
内存资源不充足时, os选择一些`最近不太会使用`的内存页, 压缩其中的数据, 从而释放出更多空闲内存. 当应用程序访问被压缩的数据时, 操作系统将其解压即可, 所有操作都在内存中完成. 相比于换出内存数据到磁
盘, 这样的做法既能够更迅速地腾出空闲内存空间, 又能够更快地恢复被压缩的数据.

linux操作系统支持的zswap机制就是一个使用内存压缩技术的例子.

### 大页
大页（hugepage）机制能够有效缓解TLB缓存项不够用的问题. 大页的大小可以是2MB甚至是1GB, 相比于4KB大小的页, 使用大页可以大幅度减少TLB的占用量（如访问2MB内存只需要1个TLB缓存项）.

在aarch64, L2页表项中存在一个特殊的位（第1位）, 它标识着这个页表项中存储的物理地址（页号）是指向L3页表页（该位是1）还是指向1个2MB的物理页（该位是0）. 同样, 如果L1页表项
的第1位是0, 就表明该项直接指向1个大小为1GB的大页.

os可利用硬件提供的大页支持, 在虚拟内存中以2MB甚至1GB的大页进行地址映射. Linux还提供了透明大页（transparent hugepage）机制, 能够自动地将1个应用程序中连续的4KB内存页合并成2MB的内存页.

> AArch64还能支持多种最小页大小, 包括4KB、16KB、64KB, os可以通过TCR_EL1寄存器迸行配置,选择需要的大小. 在ARM8.0上, 当使用16KB、64KB页大小时, 只有L2页表项支持大页功能. 比如16K时, 一个L2页表项指向的大页就是32MB, 64KB时是512MB大小的页.

## 物理内存分配与管理
### 伙伴系统
伙伴系统（buddy system）在现代os中被广泛地用于分配连续的物理内存页. 其基本思想是将物理内存划分成连续的块, 以块作为基本单位进行分配, 最小单位是一个物理页. 不同块的大小可以不同, 但每个块都由一个或多个连续的物理页组成, 物理页的数量必须是2的n次幂（0≤n＜预设的最大值）, 其中预设的最大值将决定能够分配的连续物理内存区域的最大大小, 这通常由开发者根据实际需要指定.

### slub
使用伙伴系统进行内存分配, 会出现严重的内部碎片问题, 从而导致内存资源利用率降低. slub(slab的改进版)就是分配小内存的解决方法.

SLUB分配器是为了满足os（频繁的）分配小对象的需求, 其依赖于伙伴系统进行物理页的分配. 简单来说, SLUB分配器就是把伙伴系统分配的大块内存进一步细分成小块内存进行管理. 由于操作系统频繁分配的对象大小相对比较固定, 另—方面为了避免外部碎片问题, 所以SLUB分配器只分配固定大小的内存块, 块大小通常是2^n个字节（通常3≤n<12）. 在具体实现过程中, 程序员可以根据实际需要设置一些别的大小来减少内部碎片. 对于每—种块大小, SLUB分配器都会使用独立的内存资源池进行分配.

> SLOB分配器是为了满足内存资源稀缺场景（比如嵌人式设备）的需求, 它具有最小的存储开销, 但在碎片问题的处理方面比不上其他(slab,slub)两种分配.

## 缓存染色
染色机制是操作系统有效利用缓存的一种纯软件方法, 对应的硬件实现由intel CAT, aarch64的MPAM.

## 进程/线程
线程的上下文即为AArch64架构下CPU中部分寄存器的值, 包括X0～X30共31个通用寄存器及一些特殊寄存器的值. 比如, ELR_EL1（程序计数器）、SP_EL0（线程运行时的栈指针）、SPSR_EL1（线程执行时的CPU状态, 如条件码、中断状态、是否处于调试模式等）、TTBR0_EL1（线程对应的进程的页表）这些特殊寄存器的值需要被保存.

## 总线
ARM上的片上总线规范称为高级微控制器总线结构（Advanced Micro-controller Bus Architecture, AMBA）规范, 该规范定义了ARM架构片上系统（System-on-Chip, Soc）的通信标准.

AMBA可以将ARM处理器和其他IP核进行集成, 通过对模块化的集成电路的重用, 提高片上系统的开发效率.

在AMBA规范中一共包括三组总线:
1. 高级高性能总线（Advanced High-PerfbrmanceBus, AHB）:用于连接其他高性能IP核、片上和片外内存以及中断控制器等高性能模块
1. 高级系统总线（Advanced System Bus, ASB）: 用于某些不必使用AHB但同时又需要高性能特性的芯片中, 能起到一部分降低功耗的作用
1. 高级设备总线（Advanced Peripheral Bus, APB）: 用于连接低速的设备, 作为低功耗的精简接口总线

此外, AMBA规范中还包含高级可拓展接口（Advanced eXtensible Interlace, AXI）, 它被用作高带宽、低延迟的片内总线.