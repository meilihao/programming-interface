# 调度
参考:
- [如何更改 Linux I/O 调度器来调整性能](https://linux.cn/article-8179-1.html)
- [Linux进程和线程的调度与优先级](https://vaqeteart.github.io/categories/study/os/linux_schedule_priority.html)
- [深入 Linux 的进程优先级](https://linux.cn/article-7325-1.html)
- [linux进程调度](https://peterpan980927.cn/2017/12/18/Linux%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/)

##　IO
Linux I/O 调度器Linux I/O scheduler控制内核提交读写请求给磁盘的方式. 自从 2.6 内核以来，管理员已经能够更改这个调度器，所以他们可以自定义他们的平台以完全适合他们的需要.

这些调度器是：
1. CFQ （Completely Fair Scheduler完全公平调度器）（cfq） : 它是许多 Linux 发行版的默认调度器；它将由进程提交的同步请求放到多个进程队列中，然后为每个队列分配时间片以访问磁盘
1. Noop 调度器（noop） ： 基于先入先出（FIFO）队列概念的 Linux 内核里最简单的 I/O 调度器. 此调度程序**最适合于 SSD**
1. 截止时间调度器（deadline） ： 尝试保证请求的开始服务时间

## 进程
进程可以分为CPU密集型和I/O密集型两种. I/O密集型的进程大部分时间都在用来提交I/O请求和等待I/O请求; CPU密集型进程大部分时间都花在执行代码上.

调度策略主要在两个矛盾之间寻找平衡：进程响应时间短和最大的系统利用率.

> 为了保证交互式应用和桌面系统的性能，一般Linux更倾向于优先调度I/O消耗型进程

### 进程优先级
1. nice值
nice值得优先级范围是从-20到+19，**nice值越大，优先级越小**. Linux系统的nice值代表的是时间片的比例，因此越小的nice值，占有CPU的时间也就会越长，其默认值为0.
1. 实时优先级
优先级变化范围：0~MAX_RT_PRIO-1间, 默认MAX_RT_PRIO配置为100. **值越大，优先级越高**. Linux下查看实时优先级命令： `ps -eo state,uid,pid,rtprio`

因为任何实时进程(需要尽快返回结果)的优先级都高于普通进程. 因此实时优先级和nice优先级处于两个不相交的范畴.

> `ps -el`的`NI`列包含 `-` 这个符号，该符号的含义是指：该进程是实时进程.Linux中可以通过renice命令调整进程的优先级
> `ps -eo state,uid,pid,rtprio`的`RTPRIO`列包含`-` 这个符号，该符号的含义是指：该进程不是实时进程

### 调度类型
每个Linux进程都按照以下调度类型被调度：
- SCHED_FIFO
  先进先出的实时进程, 不使用时间片. 高优先级的进程可以抢占低优先级的进程,而相同优先级的进程遵循先来先得,此时除非主动让出否则想运行多久便运行多久
- SCHED_RR
  时间片轮转的实时进程. 保证对所有相同优先级的实时进程公平地分配CPU时间即只有当它的时间片用完，内核会把它放到进程队列的末尾; 而高优先级的任务也是可以抢占低优先级的任务
- SCHED_DEADLINE
    实时进程, 按照任务的deadline进行调度的. 当产生一个调度点的时候,DL调度器总是选择其deadline距离当前时间点最近的那个任务并调度它执行
- SCHED_NORMAL
  普通的分时进程
- SCHED_BATCH
    后台进程,几乎不需要和前端进行交互, 不影响交互时可以降低它的优先级
- SCHED_IDLE
    特别空闲的时候才跑的进程

SCHED_NORMAL是普通进程调度策略,其他两者都是实时进程调度策略. 它们的主要区别就是通过优先级来区分的: 所有优先级值在0-99范围内的，都是实时进程，所以这个优先级范围也可以叫做实时进程优先级，而100-139范围内的是非实时进程.

系统的整体优先级策略是：如果系统中存在需要执行的实时进程，则优先执行实时进程. 直到实时进程退出或者主动让出CPU时，才会调度执行非实时进程. 即 **任何时候，实时进程的优先级都高于普通进程，实时进程只会被更高级的实时进程抢占，同级实时进程之间是按照FIFO（一次机会做完）或者RR（多次轮转）规则调度的**.

SCHED_FIFO 与 SCHED_RR 的区别是:当进程的调度策略为前者时,当前实时进程将一直占用 CPU 直至自动退出, **除非有更紧迫的、优先级更高的实时进程**需要运行时,它才会被抢占 CPU;当进程的调度策略为后者时,它与其它实时进程以实时轮流算法去共同使用 CPU，用完时间片放到运行队列尾部.

![Linux 进程优先级与 nice 值及实时进程优先级的关系](https://pic2.zhimg.com/80/v2-488659493625064c6227293720c117c9_hd.jpg)

> 默认情况下，进程的nice是从父进程继承来的
> priority就是ps命令中看到的PRI值或者top命令中看到的PR值, 越小说明优先级越高.
> nice值虽然不是priority，但是它确实可以影响进程的优先级
> 实时进程, 只有静态优先级;普通进程根据动态优先级进行调度
> 动态优先级(`dynamic_prio=max(100, min(static_prio-bonus+5, 139))`)是由静态优先级（`static_prio=MAX_RT_PRIO +nice+ 20`, 静态优先级范围在100~139之间）调整而来.
> 在系统中可以使用chrt命令来查看、设置一个进程的实时优先级状态
> 进程的平均睡眠时间也即bonus

1. 完全公平调度算法，简称CFS. 它是linux 默认进程调度器, 且CFS是一个普通进程的调度器. CFS的做法是：在所有可运行进程的总数上计算出一个进程应该运行的时间，nice值不再作为时间片分配的标准，而是用于处理计算获得的处理器使用权重.

### linux task_struct 调度
在task_struct中,有一个成员变量`unsigned int policy`保存了调度策略
```c
// https://sourcegraph.com/github.com/torvalds/linux@d1fdb6d/-/blob/include/uapi/linux/sched.h?utm_source=share#L17:48
/*
 * Scheduling policies
 */
#define SCHED_NORMAL		0
#define SCHED_FIFO		1
#define SCHED_RR		2
#define SCHED_BATCH		3
/* SCHED_ISO: reserved but not implemented yet */
#define SCHED_IDLE		5
#define SCHED_DEADLINE		6
```

配合调度策略的还有优先级 ,也在task_struct中
```c
// https://sourcegraph.com/github.com/torvalds/linux@d1fdb6d8f6a4109a4263176c84b899076a5f8008/-/blob/include/linux/sched.h#L649
	int				prio;
	int				static_prio;
	int				normal_prio;
	unsigned int			rt_priority;
```

优先级其实就是一个数值,对于实时进程,优先级的范围是0~99;对于普通进程,优先级的范围是100~139. 数值越小,优先级越高. 从这里可以看出,所有的实时进程都比普通进程优先级要高.

```c
const struct sched_class	*sched_class; // 调度策略的执行逻辑
```

sched_class有几种实现:
- stop_sched_class : 优先级最高的任务会使用这种策略,会中断所有其他线程,且不会被其他任务打断
- dl_sched_class : 对应上面的deadline调度策略
- rt_sched_class : 对应RR算法或者FIFO算法的调度策略,具体调度策略由进程的task_struct->policy指定;
- fair_sched_class : 普通进程的调度策略 // 对于普通进程来讲,公平是最重要的
- idle_sched_class : 空闲进程的调度策略

它们其实是放在一个链表上的,即有顺序关系.

#### 完全公平调度
在Linux里面,实现了一个基于CFS的调度算法. CFS全称Completely Fair Scheduling,叫完全公平调度

CPU会提供一个时钟,过一段时间就触发一个时钟中断Tick. CFS会为每一个进程安排一个虚拟运行时间vruntime, 如果一个进程在运行,随着时间的增长,也就是一个个tick的到来,进程的vruntime将不断增大;没有得到执行的进程vruntime不变.

显然,那些vruntime少的,原来受到了不公平的对待,需要给它补上,所以会优先运行这样的进程. 

如何结合优先级? 将实际运行时间delta_exec按照一定算法转化为虚拟运行时间vruntime即可:
```txt
虚拟运行时间vruntime += 实际运行时间delta_exec * NICE_0_LOAD/权重
```

同样的实际运行时间,给高权重的算少了,低权重的算多了,但是当选取下一个运行进程的时候,还是按照最小的vruntime来的,这样高权重的获得的实际运行时间自然就多了

因此CFS需要一个数据结构来对vruntime进行排序,找出最小的那个. 这个能够排序的数据结构不但需要查询的时候,能够快速找到最小的,更新的时候也需要能够快速的调整排序,要知道vruntime可是经常在变
的,变了再插入这个数据结构,就需要重新排序. 而能够平衡查询和更新速度的是树,在这里使用的是红黑树. 

红黑树的的节点是应该包括vruntime的,称为调度实体. 
在task_struct中有这样的成员变量:
```c
struct sched_entity se; // 完全公平算法调度实体
struct sched_rt_entity rt; // 实时调度实体
struct sched_dl_entity dl; // Deadline调度实体
```

看来不光CFS调度策略需要有这样一个数据结构进行排序,其他的调度策略也同样有自己的数据结构进行排序,因为任何一个策略做调度的时候,都是要区分谁先运行谁后运行

进程会根据自己是实时的,还是普通的类型,通过这些成员变量,将自己挂在某一个数据结构里面,和其他的进程排序,等待被调度.

对于普通进程的调度实体定义如下,这里面包含了vruntime和权重load_weight,以及对于运行时间的统计:
```c
struct sched_entity {
	/* For load-balancing: */
	struct load_weight		load;
	unsigned long			runnable_weight;
	struct rb_node			run_node;
	struct list_head		group_node;
	unsigned int			on_rq;

	u64				exec_start;
	u64				sum_exec_runtime;
	u64				vruntime;
	u64				prev_sum_exec_runtime;

	u64				nr_migrations;

	struct sched_statistics		statistics;

#ifdef CONFIG_FAIR_GROUP_SCHED
	int				depth;
	struct sched_entity		*parent;
	/* rq on which this entity is (to be) queued: */
	struct cfs_rq			*cfs_rq;
	/* rq "owned" by this entity/group: */
	struct cfs_rq			*my_q;
#endif

#ifdef CONFIG_SMP
	/*
	 * Per entity load average tracking.
	 *
	 * Put into separate cache line so it does not
	 * collide with read-mostly values above.
	 */
	struct sched_avg		avg;
#endif
};
```

所有可运行的进程通过不断地插入操作最终都存储在以时间为顺序的红黑树中,vruntime最小的在树的左侧,vruntime最多的在树的右侧. CFS调度策略会选择红黑树最左边的叶子节点作为下一个将获得cpu的任务

CPU也是这样的,每个CPU都有自己的 struct rq 结构,其用于描述在此CPU上所运行的所有进程,其包括一个实时进程队列rt_rq和一个CFS运行队列cfs_rq,在调度时,调度器首先会先去实时进程队列找是否有实时进程需要运行,如果没有才会去CFS运行队列找是否有进行需要运行

rq, rt_rq和cf_rq的定义在[`kernel/sched/sched.h](https://sourcegraph.com/github.com/torvalds/linux@d1fdb6d/-/blob/kernel/sched/sched.h?utm_source=share#L503:22)里
cfs_rq.rb_root指向的就是红黑树的根节点,这个红黑树在CPU看起来就是一个队列,不断的取下一个应该运行的进程. cfs_rq.rb_leftmost指向的是最左面的节点

![调度相关的数据结构](images/sched_rq.png)

sched_class:
```c
// https://sourcegraph.com/github.com/torvalds/linux@d1fdb6d/-/blob/kernel/sched/sched.h?utm_source=share#L807
struct sched_class {
	const struct sched_class *next; // 指向下一个调度类

	void (*enqueue_task) (struct rq *rq, struct task_struct *p, int flags);
	void (*dequeue_task) (struct rq *rq, struct task_struct *p, int flags);
	void (*yield_task)   (struct rq *rq);
	bool (*yield_to_task)(struct rq *rq, struct task_struct *p, bool preempt);

	void (*check_preempt_curr)(struct rq *rq, struct task_struct *p, int flags);

	/*
	 * It is the responsibility of the pick_next_task() method that will
	 * return the next task to call put_prev_task() on the @prev task or
	 * something equivalent.
	 *
	 * May return RETRY_TASK when it finds a higher prio class has runnable
	 * tasks.
	 */
	struct task_struct * (*pick_next_task)(struct rq *rq,
					       struct task_struct *prev,
					       struct rq_flags *rf);
	void (*put_prev_task)(struct rq *rq, struct task_struct *p);

#ifdef CONFIG_SMP
	int  (*select_task_rq)(struct task_struct *p, int task_cpu, int sd_flag, int flags);
	void (*migrate_task_rq)(struct task_struct *p, int new_cpu);

	void (*task_woken)(struct rq *this_rq, struct task_struct *task);

	void (*set_cpus_allowed)(struct task_struct *p,
				 const struct cpumask *newmask);

	void (*rq_online)(struct rq *rq);
	void (*rq_offline)(struct rq *rq);
#endif

	void (*set_curr_task)(struct rq *rq);
	void (*task_tick)(struct rq *rq, struct task_struct *p, int queued);
	void (*task_fork)(struct task_struct *p);
	void (*task_dead)(struct task_struct *p);

	/*
	 * The switched_from() call is allowed to drop rq->lock, therefore we
	 * cannot assume the switched_from/switched_to pair is serliazed by
	 * rq->lock. They are however serialized by p->pi_lock.
	 */
	void (*switched_from)(struct rq *this_rq, struct task_struct *task);
	void (*switched_to)  (struct rq *this_rq, struct task_struct *task);
	void (*prio_changed) (struct rq *this_rq, struct task_struct *task,
			      int oldprio);

	unsigned int (*get_rr_interval)(struct rq *rq,
					struct task_struct *task);

	void (*update_curr)(struct rq *rq);

#define TASK_SET_GROUP		0
#define TASK_MOVE_GROUP		1

#ifdef CONFIG_FAIR_GROUP_SCHED
	void (*task_change_group)(struct task_struct *p, int type);
#endif
};
```
这个结构定义了很多种方法,用于在队列上操作task.

```c
// https://sourcegraph.com/github.com/torvalds/linux@d1fdb6d/-/blob/kernel/sched/core.c?utm_source=share#L19
/*
 * Pick up the highest-prio task:
 */
static inline struct task_struct *
pick_next_task(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)
{
	const struct sched_class *class;
	struct task_struct *p;

	/*
	 * Optimization: we know that if all tasks are in the fair class we can
	 * call that function directly, but only if the @prev task wasn't of a
	 * higher scheduling class, because otherwise those loose the
	 * opportunity to pull in more work from other CPUs.
	 */
	if (likely((prev->sched_class == &idle_sched_class ||
		    prev->sched_class == &fair_sched_class) &&
		   rq->nr_running == rq->cfs.h_nr_running)) {

		p = fair_sched_class.pick_next_task(rq, prev, rf);
		if (unlikely(p == RETRY_TASK))
			goto again;

		/* Assumes fair_sched_class->next == idle_sched_class */
		if (unlikely(!p))
			p = idle_sched_class.pick_next_task(rq, prev, rf);

		return p;
	}

again:
	for_each_class(class) { // 沿着sched_class链表的顺序,依次调用每个调度类的方法
		p = class->pick_next_task(rq, prev, rf);
		if (p) {
			if (unlikely(p == RETRY_TASK))
				goto again;
			return p;
		}
	}

	/* The idle class should always have a runnable task: */
	BUG();
}
```

调度的时候是从优先级最高的调度类到优先级低的调度类,依次执行. 而对于每种调度类,有自己的实现CFS就是[fair_sched_class](https://sourcegraph.com/github.com/torvalds/linux@d1fdb6d8f6a4109a4263176c84b899076a5f8008/-/blob/kernel/sched/fair.c?utm_source=share#L28:24).

对于同样的pick_next_task选取下一个要运行的任务这个动作,不同的调度类有自己的实现. fair_sched_class的实现是pick_next_task_fair,rt_sched_class的实现是pick_next_task_rt. 我们会发现这两个函数是操作不同的队列,pick_next_task_rt操作的是rt_rq,pick_next_task_fair操作的是cfs_rq.

这样整个运行的场景就串起来了,在每个CPU上都有一个队列rq,这个队列里面包含多个子队列,例如rt_rq和cfs_rq,不同的队列有不同的实现方式,cfs_rq就是用红黑树实现的. 

当某个CPU需要找下一个任务执行的时候,会按照优先级依次调用调度类,不同的调度类操作不同的队列: rt_sched_class先被调用,它会在rt_rq上找下一个任务,只有找不到的时候,才轮到fair_sched_class被调用,它会在cfs_rq上找下一个任务. 这样保证了实时任务的优先级永远大于普通任务. 

看部分sched_class定义的与调度有关的函数:
- enqueue_task向就绪队列中添加一个进程,当某个进程进入可运行状态时,调用这个函数
- dequeue_task 将一个进程从就就绪队列中删除
- pick_next_task 选择接下来要运行的进程
- put_prev_task 用另一个进程代替当前运行的进程
- set_curr_task 用于修改调度策略
- task_tick 每次周期性时钟到的时候,这个函数被调用,可能触发调度

![sched全局](images/sched_task)